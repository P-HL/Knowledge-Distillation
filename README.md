# Knowledge-Distillation
About A paper list of  Knowledge-Distillation(processing).

Last updated: 2021/12/03

**Update log**
* 12.3 update [From zhang] and  some recent papers(arxiv) [From pan]


## Table of Contents
* [Datasets](https://github.com/PHL22/Knowledge-Distillation/blob/main/README.md#datasets)
* [Paper list](https://github.com/PHL22/Knowledge-Distillation#paper-list)

## Datasets


## Performance tables


## Paper list
### **From zhang**
* (cvpr 2021) [**MSAD**] Multi-Scale Aligned Distillation for Low-Resolution Detection. [[paper]](https://jiaya.me/papers/ms_align_distill_cvpr21.pdf) [[code]](https://github.com/Jia-Research-Lab/MSAD)  
* (arXiv 2019.06) [**Distilling-Object-Detectors**] Distilling Object Detectors with Fine-grained Feature Imitation. [[paper]](https://arxiv.org/abs/1906.03609v1) [[code]](https://github.com/twangnh/Distilling-Object-Detectors)
* (arXiv 2020.05) [**singleshot6Dpose**] Squeezed Deep 6DoF Object Detection Using Knowledge Distillation  --v3. [[paper]](https://arxiv.org/abs/2003.13586) [[code]](https://github.com/heitorcfelix/singleshot6Dpose)
* (arXiv 2020.06) [**StructKD**] Structured Knowledge Distillation for Dense Prediction. [[paper]](https://arxiv.org/abs/1903.04197v4) [[code]](https://git.io/StructKD)
* (arXiv 2021.02) [**LD**] Localization Distillation for Object Detection. [[paper]](https://arxiv.org/abs/2102.12252v2) [[code]](https://github.com/HikariTJU/LD)
* (arXiv 2021.03) [**DCNet**] Dense Relation Distillation with Context-aware Aggregation for Few-Shot Object Detection. [[paper]](https://arxiv.org/abs/2103.17115) [[code]](https://github.com/hzhupku/DCNet)
* (arXiv 2021.03) [**DeFeat**] Distilling Object Detectors via Decoupled Features. [[paper]](https://arxiv.org/abs/2103.14475v1) [[code]](https://github.com/ggjy/DeFeat.pytorch)
* (arXiv 2021.03) Robust and Accurate Object Detection via Adversarial Learning  --v2. [[paper]](https://arxiv.org/abs/2103.13886) [[model]](https://arxiv.org/abs/2103.13886)
* (arXiv 2021.03) [**MM-DistillNet**] There is More than Meets the Eye: Self-Supervised Multi-Object Detection and Tracking with Sound by Distilling Multimodal Knowledge. [[paper]](https://arxiv.org/abs/2103.01353v1) [[code]](https://github.com/robot-learning-freiburg/MM-DistillNet)
* (arXiv 2021.03) General Instance Distillation for Object Detection --v1. [[paper]](https://arxiv.org/abs/2103.02340v1) 
* (arXiv 2021.04) General Instance Distillation for Object Detection --v2. [[paper]](https://arxiv.org/abs/2103.02340v2)
* (arXiv 2021.04) [**ReviewKD**] Distilling Knowledge via Knowledge Review. [[paper]](https://arxiv.org/abs/2104.09044) [[code]](https://github.com/dvlab-research/ReviewKD)
* (arXiv 2021.08) [**SemSeg-distill**] Channel-wise Knowledge Distillation for Dense Prediction. [[paper]](https://arxiv.org/abs/2011.13256) [[code]](https://github.com/irfanICMLL/TorchDistiller/tree/main/SemSeg-distill)
* (arXiv 2021.09) [**Dsig**] Deep Structured Instance Graph for Distilling Object Detectors. [[paper]](https://arxiv.org/abs/2109.12862) [[code]](https://github.com/dvlab-research/Dsig)
* (arXiv 2021.10) Comprehensive Attention Self-Distillation for Weakly-Supervised Object Detection.  [[paper]](https://arxiv.org/abs/2010.12023)
* (arXiv 2021.10) [**CoLAD**] Improving Object Detection by Label Assignment Distillation  --v3. [[paper]](https://arxiv.org/abs/2108.10520v3) [[code]](https://github.com/cybercore-co-ltd/CoLAD)  



### **From pan**
* (arXiv 2021.06) Dynamic Knowledge Distillation with A Single Stream Structure for RGB-D Salient Object Detection. [[paper]](https://arxiv.org/abs/2106.09517)
* (arXiv 2021.11) Facial Landmark Points Detection Using Knowledge Distillation-Based Neural Networks. [[paper]](https://arxiv.org/abs/2111.07047)
* (arXiv 2021.04) Distilling Knowledge from Refinement in Multiple Instance Detection Networks. [[paper]](https://arxiv.org/abs/2004.10943)
* (arXiv 2021.09) Semi-Supervised Domain Generalizable Person Re-Identification  --v2. [[paper]](https://arxiv.org/abs/2108.05045v2) [[code]](https://paperswithcode.com/paper/semi-supervised-domain-generalizable-person#code)
* (arXiv 2021.08) [**OMGD**] Online Multi-Granularity Distillation for GAN Compression  --v2. [[paper]](https://arxiv.org/abs/2108.06908v2) [[code]](https://github.com/bytedance/OMGD)




#### 3D
* (arXiv 2021.09) Multi-Frame to Single-Frame: Knowledge Distillation for 3D Object Detection. [[paper]](https://arxiv.org/abs/2009.11859) 
* (arXiv 2021.06) Dynamic Knowledge Distillation with A Single Stream Structure for RGB-D Salient Object Detection. [[paper]](https://arxiv.org/abs/2106.09517)
* (arXiv 2021.05) FReTAL: Generalizing Deepfake Detection using Knowledge Distillation and Representation Learning. [[paper]](https://arxiv.org/abs/2105.13617)



#### Video
* (arXiv 2021.03) Fast Video Salient Object Detection via Spatiotemporal Knowledge Distillation  --v2. [[paper]](https://arxiv.org/abs/2010.10027) 
* (arXiv 2021.08) Learning an Augmented RGB Representation with Cross-Modal Knowledge Distillation for Action Detection. [[paper]](https://arxiv.org/abs/2108.03619)



#### New Perspective 
* (arXiv 2021.03) Revisiting Knowledge Distillation for Object Detection. [[paper]](https://arxiv.org/abs/2105.10633) 
* (arXiv 2021.10) Open-vocabulary Object Detection via Vision and Language Knowledge Distillation. [[paper]](https://arxiv.org/abs/2104.13921) 
* (arXiv 2021.07) P-KDGAN: Progressive Knowledge Distillation with GANs for One-class Novelty Detection  --v2. [[paper]](https://arxiv.org/abs/2007.06963) 

#### Instance
* (arXiv 2021.10) Instance-Conditional Knowledge Distillation for Object Detection. [[paper]](https://arxiv.org/abs/2110.12724) 

# Contact & Feedback
If you have any suggestions about this project, feel free to contact me.
* [e-mail: hlp@hbut.edu.cn]


