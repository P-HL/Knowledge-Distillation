# Knowledge-Distillation
About A paper list of  Knowledge-Distillation(processing).

**Update log**

## Table of Contents
* [Datasets](https://github.com/PHL22/Knowledge-Distillation/blob/main/README.md#datasets)
* [Paper list](https://github.com/PHL22/Knowledge-Distillation#paper-list)

## Datasets

## Paper list
**From zhang**
* 1. (arXiv 2019.06) Distilling Object Detectors with Fine-grained Feature Imitation. [[paper]](https://arxiv.org/abs/1906.03609v1) [[code]](https://github.com/twangnh/Distilling-Object-Detectors)
* 2. (arXiv 2020.05) Squeezed Deep 6DoF Object Detection Using Knowledge Distillation  --v3. [[paper]](https://arxiv.org/abs/2003.13586) [[code]](https://github.com/heitorcfelix/singleshot6Dpose)
* 3. (arXiv 2020.06) **[SKD]** Structured Knowledge Distillation for Dense Prediction. [[paper]](https://arxiv.org/abs/1903.04197v4) [[code]](https://git.io/StructKD)
* 4. (arXiv 2021.02) **[LD]** Localization Distillation for Object Detection. [[paper]](https://arxiv.org/abs/2102.12252v2) [[code]](https://github.com/HikariTJU/LD)
* 5. (arXiv 2021.03) Dense Relation Distillation with Context-aware Aggregation for Few-Shot Object Detection. [[paper]](https://arxiv.org/abs/2103.17115) [[code]](https://github.com/hzhupku/DCNet)
* 6. (arXiv 2021.03) Distilling Object Detectors via Decoupled Features. [[paper]](https://arxiv.org/abs/2103.14475v1) [[code]](https://github.com/ggjy/DeFeat.pytorch)
* 7. (arXiv 2021.03) Robust and Accurate Object Detection via Adversarial Learning  --v2. [[paper]](https://arxiv.org/abs/2103.13886) [[model]](https://arxiv.org/abs/2103.13886)
* 8. (arXiv 2021.03) There is More than Meets the Eye: Self-Supervised Multi-Object Detection and Tracking with Sound by Distilling Multimodal Knowledge. [[paper]](https://arxiv.org/abs/2103.01353v1) [[code]](https://github.com/robot-learning-freiburg/MM-DistillNet)
* 9. (arXiv 2021.03) General Instance Distillation for Object Detection --v1. [[paper]](https://arxiv.org/abs/2103.02340v1) 
* 10. (arXiv 2021.04) General Instance Distillation for Object Detection --v2. [[paper]](https://arxiv.org/abs/2103.02340v2)
* 11. (arXiv 2021.04) Distilling Knowledge via Knowledge Review. [[paper]](https://arxiv.org/abs/2104.09044) [[code]](https://github.com/dvlab-research/ReviewKD)
* 12. (arXiv 2021.08) Channel-wise Knowledge Distillation for Dense Prediction. [[paper]](https://arxiv.org/abs/2011.13256) [[code]](https://github.com/irfanICMLL/TorchDistiller/tree/main/SemSeg-distill)
* 13. (arXiv 2021.09) Deep Structured Instance Graph for Distilling Object Detectors. [[paper]](https://arxiv.org/abs/2109.12862) [[code]](https://github.com/dvlab-research/Dsig)
* 14. (arXiv 2021.10) Comprehensive Attention Self-Distillation for Weakly-Supervised Object Detection.  [[paper]](https://arxiv.org/abs/2010.12023)
* 15. (arXiv 2021.10) Improving Object Detection by Label Assignment Distillation  --v3. [[paper]](https://arxiv.org/abs/2108.10520v3) [[code]](https://github.com/cybercore-co-ltd/CoLAD)




* 1. (cvpr 2021) Multi-Scale Aligned Distillation for Low-Resolution Detection. [[paper]](https://jiaya.me/papers/ms_align_distill_cvpr21.pdf) [[code]](https://github.com/Jia-Research-Lab/MSAD)







## Paper list
**From pan**




